{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02b04b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MERGED DATA\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error # for calculating the cost function\n",
    "from sklearn.ensemble import RandomForestRegressor # for building the model\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "\n",
    "\n",
    "data = pd.read_csv('/Users/selinzobu/Desktop/TILES/111OMFITBASES111.csv', parse_dates = ['Timestamp'])\n",
    "data = data.loc[:, ~data.columns.str.contains('^Unnamed')]\n",
    "#fitbit[\"Timestamp\"] = pd.to_datetime(fitbit[\"Timestamp\"], utc=True)\n",
    "#print(data.columns)\n",
    "\n",
    "bases = pd.read_csv('/Users/selinzobu/Desktop/TILES/1BASESTRESSD.csv', parse_dates = ['Timestamp'])\n",
    "bases = bases.loc[:, ~bases.columns.str.contains('^Unnamed')]\n",
    "\n",
    "FOM = pd.read_csv('/Users/selinzobu/Desktop/TILES/1FITOMSTRESSD.csv', parse_dates = ['Timestamp'])\n",
    "FOM = FOM.loc[:, ~FOM.columns.str.contains('^Unnamed')]\n",
    "\n",
    "X = data.iloc[:,2:65]  #independent columns\n",
    "X = X.drop('days', axis = 1)\n",
    "y = data.iloc[:,-1]    #target column \n",
    "\n",
    "X_base = bases.drop(['participant_id', 'Timestamp', 'mstressd'], axis = 1)  #independent columns\n",
    "y_base = bases['mstressd']    #target column \n",
    "\n",
    "X_FOM = FOM.drop(['participant_id', 'Timestamp', 'mstressd', 'days'], axis = 1)  #independent columns\n",
    "y_FOM = FOM['mstressd']   #target column \n",
    "\n",
    "#for col in X.columns:\n",
    " #   X[col] = X[col].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03950679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2989\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "2984\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(type(data))\n",
    "print(len(data.groupby(['Timestamp', 'participant_id'])['mstressd'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec618012",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X[['AvgHeartRateS', 'RMSStdDev_msM', 'AvgBreathingRateM', 'AvgZAccel_gM', 'StdDevBreathingRateM', 'Fat Burn_caloriesOut', 'NumberSteps', 'iod_ID', 'iod_OD', 'ocb', 'pan_NegAffect', 'stai', 'rand_EmotionalWellbeing', 'swls', 'pss', 'mpfi_Flexibility_Defusion', 'pcq_Hope', 'pcq_Optimism', 'chss_ChallengeStressors', 'chss_HindranceStressors']]\n",
    "\n",
    "X2_FOM = X_FOM[['Cardio_caloriesOut', 'AvgHeartRateS', 'RMSStdDev_msM', 'AvgBreathingRateM', 'AvgYAccel_gM', 'AvgZAccel_gM', 'StdDevBreathingRateM', 'StdDevBreathingRateS', 'StdDevGForceM', 'StdDevYAccel_gM']]\n",
    "\n",
    "X2_base = X_base[['rand_EmotionalWellbeing', 'ocb', 'pcq_Hope', 'mpfi_Flexibility_Defusion', 'mpfi_Flexibility_SelfAsContext', 'iod_ID', 'mpfi_Flexibility_PresentMomentAwareness', 'swls', 'chss_ChallengeStressors', 'stai', 'pan_NegAffect']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75a77f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2989, 20) (3126, 10) (7868, 11) (2989,)\n"
     ]
    }
   ],
   "source": [
    "print(X2.shape, X2_FOM.shape, X2_base.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67d59da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y_train, y_test = train_test_split(\n",
    "    X2, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X2b_train, X2b_test, yb_train, yb_test = train_test_split(\n",
    "    X2_base, y_base, test_size=0.3, random_state=42)\n",
    "\n",
    "X2FOM_train, X2FOM_test, yFOM_train, yFOM_test = train_test_split(\n",
    "    X2_FOM, y_FOM, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd7defa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X2_train: (2092, 20) X2_test: (897, 20) y_train: (2092,) y_test: (897,)\n",
      "X2b_train: (5507, 11) X2b_test: (2361, 11) yb_train: (5507,) yb_test: (2361,)\n",
      "X2FOM_train: (2188, 10) X2FOM_test: (938, 10) yFOM_train: (2188,) yFOM_test: (938,)\n"
     ]
    }
   ],
   "source": [
    "print('X2_train:', X2_train.shape, 'X2_test:', X2_test.shape, 'y_train:', y_train.shape,'y_test:', y_test.shape)\n",
    "#print(y_test.head())\n",
    "print('X2b_train:', X2b_train.shape, 'X2b_test:', X2b_test.shape, 'yb_train:', yb_train.shape,'yb_test:', yb_test.shape)\n",
    "#print(yb_test.head())\n",
    "print('X2FOM_train:', X2FOM_train.shape, 'X2FOM_test:', X2FOM_test.shape, 'yFOM_train:', yFOM_train.shape,'yFOM_test:', yFOM_test.shape)\n",
    "#print(yFOM_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdebaf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.902963671128107 (2092,) 1.803068821499909 (5507,) 1.9079067641681902 (2188,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.mean(), y_train.shape, yb_train.mean(),yb_train.shape, yFOM_train.mean(), yFOM_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5731d14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAverage baseline error merged:  0.75\n",
      "TAverage baseline error baseline:  0.75\n",
      "TAverage baseline error FOM:  0.73\n",
      "897 2361 938\n"
     ]
    }
   ],
   "source": [
    "#The baseline prediction for our case can be the historical stress score averages. \n",
    "#In other words, our baseline is the error we would get if we simply predicted the average\n",
    "#stress score for all days.\n",
    "\n",
    "# The baseline predictions are the historical averages\n",
    "Mbaseline_preds = y_train.mean()\n",
    "Bbaseline_preds = yb_train.mean()\n",
    "FOMbaseline_preds = yFOM_train.mean()\n",
    "\n",
    "# Baseline errors, and display average baseline error\n",
    "Mbaseline_errors = abs(Mbaseline_preds - y_test)\n",
    "Bbaseline_errors = abs(Bbaseline_preds - yb_test)\n",
    "FOMbaseline_errors = abs(FOMbaseline_preds - yFOM_test)\n",
    "\n",
    "\n",
    "print('TAverage baseline error merged: ', round(np.mean(Mbaseline_errors), 2))\n",
    "print('TAverage baseline error baseline: ', round(np.mean(Bbaseline_errors), 2))\n",
    "print('TAverage baseline error FOM: ', round(np.mean(FOMbaseline_errors), 2))\n",
    "\n",
    "\n",
    "print(len(Mbaseline_errors), len(Bbaseline_errors), len(FOMbaseline_errors))\n",
    "\n",
    "Mbaseline_errors = list(Mbaseline_errors)\n",
    "Bbaseline_errors = list(Bbaseline_errors)\n",
    "FOMbaseline_errors = list(FOMbaseline_errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa8d9cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=200, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=200, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=200, random_state=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Random Forest Regression to the dataset\n",
    "# import the regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "  \n",
    "# create regressor object\n",
    "regressor = RandomForestRegressor(n_estimators = 200, random_state = 0)\n",
    "  \n",
    "# fit the regressor with x and y data\n",
    "regressor.fit(X2_train, y_train)  \n",
    "\n",
    "#model.fit(Xb_train, yb_train)\n",
    "#model.fit(XFOM_train, yFOM_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54314205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=200, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=200, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=200, random_state=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BASELINE\n",
    "#Fitting Random Forest Regression to the dataset\n",
    "# import the regressor\n",
    "\n",
    "# create regressor object\n",
    "regressor = RandomForestRegressor(n_estimators = 200, random_state = 0)\n",
    "  \n",
    "# fit the regressor with x and y data\n",
    "regressor.fit(X2b_train, yb_train)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ba86f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=200, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=200, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=200, random_state=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FOM\n",
    "#Fitting Random Forest Regression to the dataset\n",
    "# import the regressor\n",
    "\n",
    "# create regressor object\n",
    "regressor = RandomForestRegressor(n_estimators = 200, random_state = 0)\n",
    "  \n",
    "# fit the regressor with x and y data\n",
    "regressor.fit(X2FOM_train, yFOM_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c311174d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE:  0.771\n"
     ]
    }
   ],
   "source": [
    "# Predicting the target values of the test set\n",
    "y2_pred = regressor.predict(X2_test)\n",
    "\n",
    "# RMSE (Root Mean Square Error)\n",
    "rmse = float(format(np.sqrt(mean_squared_error(y_test, y2_pred)), '.3f'))\n",
    "print(\"\\nRMSE: \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04e7dd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE:  0.762\n"
     ]
    }
   ],
   "source": [
    "# BASELINE\n",
    "#Predicting the target values of the test set\n",
    "y2b_pred = regressor.predict(X2b_test)\n",
    "\n",
    "# RMSE (Root Mean Square Error)\n",
    "rmse = float(format(np.sqrt(mean_squared_error(yb_test, y2b_pred)), '.3f'))\n",
    "print(\"\\nRMSE: \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d580ccf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE:  0.835\n"
     ]
    }
   ],
   "source": [
    "# FOM\n",
    "#Predicting the target values of the test set\n",
    "y2FOM_pred = regressor.predict(X2FOM_test)\n",
    "\n",
    "# RMSE (Root Mean Square Error)\n",
    "rmse = float(format(np.sqrt(mean_squared_error(yFOM_test, y2FOM_pred)), '.3f'))\n",
    "print(\"\\nRMSE: \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f44bdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.6 degrees.\n"
     ]
    }
   ],
   "source": [
    "# Calculate the absolute errors\n",
    "errors = abs(y2_pred - y_test)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fd83856e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.59 degrees.\n"
     ]
    }
   ],
   "source": [
    "# BASELINE\n",
    "#Calculate the absolute errors\n",
    "errors = abs(y2b_pred - yb_test)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08b5afc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.68 degrees.\n"
     ]
    }
   ],
   "source": [
    "# FOM\n",
    "#Calculate the absolute errors\n",
    "errors = abs(y2FOM_pred - yFOM_test)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3954a685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.14 %.\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / y_test)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "165f1363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.39 %.\n"
     ]
    }
   ],
   "source": [
    "#BASELINE\n",
    "#Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / yb_test)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "45683a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 56.52 %.\n"
     ]
    }
   ],
   "source": [
    "#FOM\n",
    "#Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / yFOM_test)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "98614112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AvgHeartRateS', 'RMSStdDev_msM', 'AvgBreathingRateM', 'AvgZAccel_gM', 'StdDevBreathingRateM', 'Fat Burn_caloriesOut', 'NumberSteps', 'iod_ID', 'iod_OD', 'ocb', 'pan_NegAffect', 'stai', 'rand_EmotionalWellbeing', 'swls', 'pss', 'mpfi_Flexibility_Defusion', 'pcq_Hope', 'pcq_Optimism', 'chss_ChallengeStressors', 'chss_HindranceStressors']\n"
     ]
    }
   ],
   "source": [
    "feature_list = list(X2.columns)\n",
    "print(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "461d1678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pydot\n",
    "#!pip install graphviz\n",
    "#!install gprof2dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "609197eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: StdDevBreathingRateM Importance: 0.1\n",
      "Variable: RMSStdDev_msM        Importance: 0.09\n",
      "Variable: AvgBreathingRateM    Importance: 0.09\n",
      "Variable: AvgZAccel_gM         Importance: 0.09\n",
      "Variable: NumberSteps          Importance: 0.09\n",
      "Variable: AvgHeartRateS        Importance: 0.08\n",
      "Variable: Fat Burn_caloriesOut Importance: 0.08\n",
      "Variable: chss_ChallengeStressors Importance: 0.07\n",
      "Variable: mpfi_Flexibility_Defusion Importance: 0.06\n",
      "Variable: rand_EmotionalWellbeing Importance: 0.04\n",
      "Variable: iod_ID               Importance: 0.03\n",
      "Variable: pan_NegAffect        Importance: 0.03\n",
      "Variable: stai                 Importance: 0.03\n",
      "Variable: iod_OD               Importance: 0.02\n",
      "Variable: ocb                  Importance: 0.02\n",
      "Variable: swls                 Importance: 0.02\n",
      "Variable: pss                  Importance: 0.02\n",
      "Variable: pcq_Hope             Importance: 0.02\n",
      "Variable: pcq_Optimism         Importance: 0.02\n",
      "Variable: chss_HindranceStressors Importance: 0.02\n"
     ]
    }
   ],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(regressor.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "910a020f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: iod_OD               Importance: 0.17\n",
      "Variable: AvgHeartRateS        Importance: 0.11\n",
      "Variable: Fat Burn_caloriesOut Importance: 0.11\n",
      "Variable: pan_NegAffect        Importance: 0.11\n",
      "Variable: iod_ID               Importance: 0.1\n",
      "Variable: RMSStdDev_msM        Importance: 0.08\n",
      "Variable: ocb                  Importance: 0.08\n",
      "Variable: AvgZAccel_gM         Importance: 0.07\n",
      "Variable: AvgBreathingRateM    Importance: 0.06\n",
      "Variable: StdDevBreathingRateM Importance: 0.06\n",
      "Variable: NumberSteps          Importance: 0.05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BASELINE\n",
    "#Get numerical feature importances\n",
    "importances = list(regressor.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ad18b1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: AvgBreathingRateM    Importance: 0.12\n",
      "Variable: AvgZAccel_gM         Importance: 0.11\n",
      "Variable: StdDevBreathingRateM Importance: 0.11\n",
      "Variable: Fat Burn_caloriesOut Importance: 0.11\n",
      "Variable: RMSStdDev_msM        Importance: 0.1\n",
      "Variable: NumberSteps          Importance: 0.1\n",
      "Variable: iod_ID               Importance: 0.1\n",
      "Variable: iod_OD               Importance: 0.1\n",
      "Variable: ocb                  Importance: 0.1\n",
      "Variable: AvgHeartRateS        Importance: 0.06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FOM\n",
    "#Get numerical feature importances\n",
    "importances = list(regressor.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09ca9084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training results and best parameters\n",
    "\n",
    "def model_train(X_t, y_t):\n",
    "# Perform Grid-Search\n",
    "    param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [2, 3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 400]}\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=RandomForestRegressor(random_state =0),\n",
    "        param_grid=param_grid,\n",
    "        cv=KFold(n_splits=5, shuffle=True, random_state=1),\n",
    "        scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "    \n",
    "    grid_result = grid_search.fit(X_t, y_t)\n",
    "    best_params = grid_result.best_params_\n",
    "\n",
    "    \n",
    "    rf = RandomForestRegressor(bootstrap = grid_search.best_params_['bootstrap'],\n",
    "                           n_estimators = grid_search.best_params_['n_estimators'],\n",
    "                           max_features = grid_search.best_params_['max_features'],\n",
    "                           max_depth = grid_search.best_params_['max_depth'],\n",
    "                           min_samples_leaf = grid_search.best_params_['min_samples_leaf'],\n",
    "                           min_samples_split = grid_search.best_params_['min_samples_split'],\n",
    "                           random_state = 0)\n",
    "# Perform K-Fold CV\n",
    "    trainscores = cross_val_score(rf, X_t, y_t, cv=10, scoring='neg_mean_absolute_error')\n",
    "    train_n_scores = cross_val_score(rf, X_t, y_t,\n",
    "                           cv=KFold(n_splits=5, shuffle=True, random_state=1)).mean()\n",
    "    \n",
    "    return 'bestparameters;', best_params, 'MAE:', trainscores.mean(), train_n_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f827291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'bootstrap': True, 'max_depth': 80, 'max_features': 3, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 400}, -0.5762064386433006, 0.29703392472767015)\n"
     ]
    }
   ],
   "source": [
    "#MULTIMODAL TRAIN RESULTS\n",
    "\n",
    "print(model_train(X2_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bb07461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'bootstrap': True, 'max_depth': 80, 'max_features': 3, 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 100}, -0.574937723095504, 0.28458706604493317)\n"
     ]
    }
   ],
   "source": [
    "#BASELINE TRAIN RESULTS\n",
    "\n",
    "print(model_train(X2b_train, yb_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90555578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bestparameters;', {'bootstrap': True, 'max_depth': 80, 'max_features': 2, 'min_samples_leaf': 2, 'min_samples_split': 8, 'n_estimators': 100}, 'MAE:', -0.6942228831994853, 0.12596278346944778)\n"
     ]
    }
   ],
   "source": [
    "#FOM TRAIN RESULTS\n",
    "\n",
    "print(model_train(X2FOM_train, yFOM_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b5ddcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAE: 0.589500167854654 897\n"
     ]
    }
   ],
   "source": [
    "#Multimodal Errors\n",
    "\n",
    "MRF_errors = []\n",
    "    \n",
    "\n",
    "best_param = {'bootstrap': True, 'max_depth': 80, 'max_features': 3, \n",
    "                'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 400}\n",
    "    \n",
    "rf = RandomForestRegressor(bootstrap = best_param['bootstrap'],\n",
    "                           n_estimators = best_param['n_estimators'],\n",
    "                           max_features = best_param['max_features'],\n",
    "                           max_depth = best_param['max_depth'],\n",
    "                           min_samples_leaf = best_param['min_samples_leaf'],\n",
    "                           min_samples_split = best_param['min_samples_split'],\n",
    "                           random_state = 0)\n",
    "\n",
    "rf.fit(X2_train, y_train.ravel())\n",
    "y_pred = rf.predict(X2_test)\n",
    "\n",
    "MRF_errors = abs(y_pred - y_test)\n",
    "\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"\\nMAE:\", mae, len(MRF_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8137662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergedmodel_test(X_t, y_t, X_test, y_test):\n",
    "    best_param = {'bootstrap': True, 'max_depth': 80, \n",
    "                  'max_features': 3, 'min_samples_leaf': 4, 'min_samples_split': 10,\n",
    "                  'n_estimators': 400}\n",
    "    \n",
    "    rf = RandomForestRegressor(bootstrap = best_param['bootstrap'],\n",
    "                           n_estimators = best_param['n_estimators'],\n",
    "                           max_features = best_param['max_features'],\n",
    "                           max_depth = best_param['max_depth'],\n",
    "                           min_samples_leaf = best_param['min_samples_leaf'],\n",
    "                           min_samples_split = best_param['min_samples_split'],\n",
    "                           random_state = 0)\n",
    "# Perform K-Fold CV\n",
    "    scores = cross_val_score(rf, X_test, y_test, cv=10, scoring='neg_mean_absolute_error')\n",
    "    n_scores = cross_val_score(rf, X_test, y_test,\n",
    "                           cv=KFold(n_splits=5, shuffle=True, random_state=1)).mean()\n",
    "\n",
    "    rf.fit(X_t, y_t)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    rmse = float(format(np.sqrt(mean_squared_error(y_test, y_pred)), '.3f'))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "\n",
    "    return scores.mean(), \"\\RMSE: \", rmse, '\\nMAE: ', mae, '\\nMSE: ', mse, n_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0d26378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.6277521718453076, '\\\\RMSE: ', 0.748, '\\nMAE: ', 0.589500167854654, '\\nMSE: ', 0.5591977088624736, 0.23996831875476543)\n"
     ]
    }
   ],
   "source": [
    "#MULTIMODAL -TEST RESULTS \n",
    "print(mergedmodel_test(X2_train, y_train, X2_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc095aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAE: 0.5881430306797508 2361\n"
     ]
    }
   ],
   "source": [
    "#Baseline Errors\n",
    "\n",
    "BRF_errors = []\n",
    "    \n",
    "best_param = {'bootstrap': True, 'max_depth': 80, 'max_features': 3, \n",
    "                   'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 100}\n",
    "    \n",
    "rf = RandomForestRegressor(bootstrap = best_param['bootstrap'],\n",
    "                           n_estimators = best_param['n_estimators'],\n",
    "                           max_features = best_param['max_features'],\n",
    "                           max_depth = best_param['max_depth'],\n",
    "                           min_samples_leaf = best_param['min_samples_leaf'],\n",
    "                           min_samples_split = best_param['min_samples_split'],\n",
    "                           random_state = 0)\n",
    "\n",
    "rf.fit(X2b_train, yb_train.ravel())\n",
    "y_pred = rf.predict(X2b_test)\n",
    "\n",
    "BRF_errors = abs(y_pred - yb_test)\n",
    "\n",
    "\n",
    "mae = mean_absolute_error(yb_test, y_pred)\n",
    "\n",
    "print(\"\\nMAE:\", mae, len(BRF_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "300414b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basemodel_test(X_t, y_t, X_test, y_test):\n",
    "    best_param = {'bootstrap': True, 'max_depth': 80, 'max_features': 3, \n",
    "                   'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 100}\n",
    "    \n",
    "    rf = RandomForestRegressor(bootstrap = best_param['bootstrap'],\n",
    "                           n_estimators = best_param['n_estimators'],\n",
    "                           max_features = best_param['max_features'],\n",
    "                           max_depth = best_param['max_depth'],\n",
    "                           min_samples_leaf = best_param['min_samples_leaf'],\n",
    "                           min_samples_split = best_param['min_samples_split'],\n",
    "                           random_state = 0)\n",
    "# Perform K-Fold CV\n",
    "    scores = cross_val_score(rf, X_test, y_test, cv=10, scoring='neg_mean_absolute_error')\n",
    "    n_scores = cross_val_score(rf, X_test, y_test,\n",
    "                           cv=KFold(n_splits=5, shuffle=True, random_state=1)).mean()\n",
    "\n",
    "    rf.fit(X_t, y_t)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    rmse = float(format(np.sqrt(mean_squared_error(y_test, y_pred)), '.3f'))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "\n",
    "    return scores.mean(), \"\\RMSE: \", rmse, '\\nMAE: ', mae, '\\nMSE: ', mse, n_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6453b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.5990334144625866, '\\\\RMSE: ', 0.761, '\\nMAE: ', 0.5881430306797508, '\\nMSE: ', 0.5789009689613209, 0.24408892416043626)\n"
     ]
    }
   ],
   "source": [
    "#BASELINE - TEST RESULTS\n",
    "\n",
    "print(basemodel_test(X2b_train, yb_train, X2b_test, yb_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e98ee30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAE: 0.6752463569759651 938\n"
     ]
    }
   ],
   "source": [
    "#FOM Errors\n",
    "\n",
    "FOMRF_errors = []\n",
    "    \n",
    "best_param = {'bootstrap': True, 'max_depth': 80, 'max_features': 2, \n",
    "                  'min_samples_leaf': 2, 'min_samples_split': 8, 'n_estimators': 100}\n",
    "    \n",
    "rf = RandomForestRegressor(bootstrap = best_param['bootstrap'],\n",
    "                           n_estimators = best_param['n_estimators'],\n",
    "                           max_features = best_param['max_features'],\n",
    "                           max_depth = best_param['max_depth'],\n",
    "                           min_samples_leaf = best_param['min_samples_leaf'],\n",
    "                           min_samples_split = best_param['min_samples_split'],\n",
    "                           random_state = 0)\n",
    "\n",
    "rf.fit(X2FOM_train, yFOM_train.ravel())\n",
    "y_pred = rf.predict(X2FOM_test)\n",
    "\n",
    "FOMRF_errors = abs(y_pred - yFOM_test)\n",
    "\n",
    "\n",
    "mae = mean_absolute_error(yFOM_test, y_pred)\n",
    "\n",
    "print(\"\\nMAE:\", mae, len(FOMRF_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3eef5b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FOMmodel_test(X_t, y_t, X_test, y_test):\n",
    "    best_param = {'bootstrap': True, 'max_depth': 80, 'max_features': 2, \n",
    "                  'min_samples_leaf': 2, 'min_samples_split': 8, 'n_estimators': 100}\n",
    "    \n",
    "    rf = RandomForestRegressor(bootstrap = best_param['bootstrap'],\n",
    "                           n_estimators = best_param['n_estimators'],\n",
    "                           max_features = best_param['max_features'],\n",
    "                           max_depth = best_param['max_depth'],\n",
    "                           min_samples_leaf = best_param['min_samples_leaf'],\n",
    "                           min_samples_split = best_param['min_samples_split'],\n",
    "                           random_state = 0)\n",
    "# Perform K-Fold CV\n",
    "    scores = cross_val_score(rf, X_test, y_test, cv=10, scoring='neg_mean_absolute_error')\n",
    "    n_scores = cross_val_score(rf, X_test, y_test,\n",
    "                           cv=KFold(n_splits=5, shuffle=True, random_state=1)).mean()\n",
    "\n",
    "    rf.fit(X_t, y_t)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    rmse = float(format(np.sqrt(mean_squared_error(y_test, y_pred)), '.3f'))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "\n",
    "    return scores.mean(), \"\\RMSE: \", rmse, '\\nMAE: ', mae, '\\nMSE: ', mse, n_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5a09b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.6998335585495488, '\\\\RMSE: ', 0.826, '\\nMAE: ', 0.6752463569759651, '\\nMSE: ', 0.6825073887358436, 0.07745614694963285)\n"
     ]
    }
   ],
   "source": [
    "#FOM - TEST RESULTS\n",
    "\n",
    "print(FOMmodel_test(X2FOM_train, yFOM_train, X2FOM_test, yFOM_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "434f629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another attempt with CV and Grid Search\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "def rfr_model(X_t, y_t, X_te, y_te):\n",
    "# Perform Grid-Search\n",
    "    param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [2, 3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 400]}\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=RandomForestRegressor(random_state =0),\n",
    "        param_grid=param_grid,\n",
    "        cv=KFold(n_splits=5, shuffle=True, random_state=1),\n",
    "        scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "    \n",
    "    grid_result = grid_search.fit(X_t, y_t)\n",
    "    best_params = grid_result.best_params_\n",
    "    \n",
    "   # rfr = RandomForestRegressor(max_depth=best_params[\"max_depth\"], \n",
    "  #  n_estimators=best_params[\"n_estimators\"],random_state=False, verbose=False)\n",
    "    rf = RandomForestRegressor(bootstrap = grid_search.best_params_['bootstrap'],\n",
    "                           n_estimators = grid_search.best_params_['n_estimators'],\n",
    "                           max_features = grid_search.best_params_['max_features'],\n",
    "                           max_depth = grid_search.best_params_['max_depth'],\n",
    "                           min_samples_leaf = grid_search.best_params_['min_samples_leaf'],\n",
    "                           min_samples_split = grid_search.best_params_['min_samples_split'],\n",
    "                           random_state = 0)\n",
    "# Perform K-Fold CV\n",
    "    scores = cross_val_score(rf, X_t, y_t, cv=10, scoring='neg_mean_absolute_error')\n",
    "    #n_scores = cross_val_score(rf, X_t, y_t,\n",
    "                           cv=KFold(n_splits=5, shuffle=True, random_state=1)).mean()\n",
    "    #rfr.fit(X_t, y_t)\n",
    "    rf.fit(X_t, y_t)\n",
    "    y_pred = rf.predict(X_te)\n",
    "    rmse = float(format(np.sqrt(mean_squared_error(y_te, y_pred)), '.3f'))\n",
    "    mae = mean_absolute_error(y_te, y_pred)\n",
    "    mse = mean_squared_error(y_te, y_pred)\n",
    "    \n",
    "\n",
    "    return scores, \"\\RMSE: \", rmse, '\\nMAE: ', mae, '\\nMSE: ', mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "82532912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.59621487, -0.58066229, -0.59790671, -0.60217617, -0.58514583,\n",
       "        -0.51574472, -0.57896342, -0.56638479, -0.58000919, -0.55885639]),\n",
       " '\\\\RMSE: ',\n",
       " 0.748,\n",
       " '\\nMAE: ',\n",
       " 0.589500167854654,\n",
       " '\\nMSE: ',\n",
       " 0.5591977088624736,\n",
       " 0.29703392472767015)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr_model(X2_train, y_train, X2_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75db8c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boruta is based on random forest, which is an ensemble of decision trees. Decision trees\n",
    "#do not need to be scaled, because selecting a split on one scale is equivalent to \n",
    "#selecting a re-scaled split on an alternative scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af98e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the Random Forest Regression results\n",
    "  \n",
    "# arrange for creating a range of values\n",
    "# from min value of x to max \n",
    "# value of x with a difference of 0.01 \n",
    "# between two consecutive values\n",
    "X_grid = np.arrange(min(x), max(x), 0.01) \n",
    "  \n",
    "# reshape for reshaping the data into a len(X_grid)*1 array, \n",
    "# i.e. to make a column out of the X_grid value                  \n",
    "X_grid = X_grid.reshape((len(X_grid), 1))\n",
    "  \n",
    "# Scatter plot for original data\n",
    "plt.scatter(x, y, color = 'blue')  \n",
    "  \n",
    "# plot predicted data\n",
    "plt.plot(X_grid, regressor.predict(X_grid), \n",
    "         color = 'green') \n",
    "plt.title('Random Forest Regression')\n",
    "plt.xlabel('Position level')\n",
    "plt.ylabel('Salary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc1df633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938 938\n",
      "2361 2361\n",
      "897 897\n"
     ]
    }
   ],
   "source": [
    "# SIGNIFICANCE OF DIFFERENCE\n",
    "\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "\n",
    "\n",
    "print(len(FOMRF_errors), len(FOMbaseline_errors))\n",
    "print(len(BRF_errors), len(Bbaseline_errors))\n",
    "print(len(MRF_errors), len(Mbaseline_errors))\n",
    "\n",
    "\n",
    "os.makedirs('/Users/selinzobu/Desktop/TILES/', exist_ok=True)  \n",
    "MRF_errors.to_csv('/Users/selinzobu/Desktop/TILES/1MRFERRORS.csv') \n",
    "BRF_errors.to_csv('/Users/selinzobu/Desktop/TILES/1BRFERRORS.csv') \n",
    "FOMRF_errors.to_csv('/Users/selinzobu/Desktop/TILES/1FOMRFERRORS.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe557d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(897,)\n",
      "1011    0.198245\n",
      "1913    0.170930\n",
      "783     0.518097\n",
      "1600    0.262431\n",
      "324     0.260553\n",
      "          ...   \n",
      "1263    0.244976\n",
      "2236    0.582756\n",
      "2939    0.084449\n",
      "632     1.115347\n",
      "1763    0.606265\n",
      "Name: mstressd, Length: 897, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(MRF_errors.shape)\n",
    "print(MRF_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5e7ffe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WilcoxonResult(statistic=121107.0, pvalue=4.566381071990293e-25)\n",
      "WilcoxonResult(statistic=169749.0, pvalue=1.2158871042288187e-09)\n",
      "WilcoxonResult(statistic=839708.0, pvalue=7.023825678919594e-63)\n"
     ]
    }
   ],
   "source": [
    "#conduct the Wilcoxon-Signed Rank Test\n",
    "\n",
    "Mdif = stats.wilcoxon(MRF_errors, Mbaseline_errors)\n",
    "FOMdif = stats.wilcoxon(FOMRF_errors, FOMbaseline_errors)\n",
    "Bdif = stats.wilcoxon(BRF_errors, Bbaseline_errors)\n",
    "\n",
    "print(Mdif)\n",
    "print(FOMdif)\n",
    "print(Bdif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a6e10d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0000000000000000000000000000'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:.28f}\".format(float(\"7.023825678919594e-63\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15b466e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c00040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
